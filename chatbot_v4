import warnings
warnings.filterwarnings("ignore")

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppresses TensorFlow warnings

import nltk
nltk.download('stopwords')
nltk.download('punkt')  # Ensure stopwords and tokenizer are available
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
import pandas as pd
from transformers import pipeline
import language_tool_python
import re
import textwrap
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
import streamlit as st

# Initialize the spell checker
tool = language_tool_python.LanguageTool('en-US')

# Load your DataFrame (adjust the path to your actual CSV file)
@st.cache_data  # Caches the data for better performance
def load_data():
    df = pd.read_csv(r"C:\Users\Jay\Documents\Sem 5\NLP\Chatbot\Chatbot\cleaned_medical_qa.csv")
    return df

df = load_data()

# Initialize stemmer, lemmatizer, and stop words
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

# Function to preprocess the question
def preprocess_question(question):
    words = nltk.word_tokenize(question.lower())
    keywords = [stemmer.stem(lemmatizer.lemmatize(word)) for word in words if word.isalpha() and word not in stop_words]
    return " ".join(keywords)

# Apply the preprocessing to the "question" column and create a new "keywords" column
df['keywords'] = df['question'].apply(preprocess_question)

# Combine all rows in 'answer' column within each focus_area group
grouped_df = df.groupby('focus_area').agg({'answer': ' '.join}).reset_index()

# Create a dictionary where the key is the focus area and the value is the combined answers
focus_area_dict = {focus_area: group['answer'].iloc[0] for focus_area, group in grouped_df.groupby('focus_area')}

# Function to correct spelling mistakes
def correct_spelling(input_text):
    matches = tool.check(input_text)
    corrected_text = language_tool_python.utils.correct(input_text, matches)
    return corrected_text

# Function to preprocess user input and return corrected input
def preprocess_input(user_input):
    corrected_input = correct_spelling(user_input)
    words = nltk.word_tokenize(corrected_input.lower())
    words = [word for word in words if word.isalpha()]
    keywords = [stemmer.stem(lemmatizer.lemmatize(word)) for word in words if word not in stop_words]
    return " ".join(keywords), corrected_input

# Initialize the BERT-base uncased model for question answering
qa_pipeline = pipeline("question-answering", model="bert-base-uncased", tokenizer="bert-base-uncased")

# Function to get an answer using BERT
def get_answer_from_bert(question, context):
    qa_input = {
        'question': question,
        'context': context
    }
    return qa_pipeline(qa_input)['answer']

# Function to clean the summary generated by Sumy
def clean_summary(summary):
    summary = re.sub(r'[^\w\s\.\,\!\?]', '', summary)
    summary = re.sub(r'\s+', ' ', summary).strip()
    summary = re.sub(r'\.+', '.', summary)
    summary = re.sub(r'\?+', '?', summary)
    summary = re.sub(r'!+', '!', summary)
    return summary

# Function to summarize the answer using Sumy, excluding the first two sentences
def summarize_answer(answer):
    try:
        # Split the answer into sentences
        sentences = re.split(r'(?<=[.!?]) +', answer)  # Split at sentence boundaries
        
        # Keep the first two sentences intact
        first_two_sentences = " ".join(sentences[:2])  # Get the first two sentences

        # Only summarize the remaining sentences
        remaining_text = " ".join(sentences[2:])

        if remaining_text:
            # Parse the remaining text for summarization
            parser = PlaintextParser.from_string(remaining_text, Tokenizer("english"))
            summarizer = LsaSummarizer()
            summary = summarizer(parser.document, 5)  # Summarize remaining sentences to 5 sentences
            
            # Join the summarized sentences
            summarized_content = " ".join([str(sentence) for sentence in summary])

            # Combine the first two sentences with the summarized content
            final_summary = f"{first_two_sentences} {summarized_content}"
        else:
            # If there are no remaining sentences, just return the first two sentences
            final_summary = first_two_sentences

        return clean_summary(final_summary)  # Clean the combined summary
    except Exception as e:
        print(f"Error summarizing answer: {e}")
        return answer


# Function to beautify the answer with proper formatting
def beautify_answer(answer, width=80):
    wrapped_answer = textwrap.fill(answer, width=width)
    return wrapped_answer

# Function to find exact match
def find_exact_match(user_input):
    input_keywords, corrected_input = preprocess_input(user_input)
    for index, row in df.iterrows():
        if set(input_keywords.split()) == set(row['keywords'].split()):
            return row['answer'], row['source'], corrected_input
    return None, None, corrected_input

# Function to find best match using BERT
def find_best_match(user_input):
    input_keywords, corrected_input = preprocess_input(user_input)

    matched_focus_area = None
    for focus_area in focus_area_dict.keys():
        if input_keywords in preprocess_question(focus_area):
            matched_focus_area = focus_area
            break

    if matched_focus_area:
        context = focus_area_dict[matched_focus_area]
        answer = get_answer_from_bert(user_input, context)
        return answer, matched_focus_area, corrected_input
    else:
        return "Sorry, I couldn't find a close enough match.", None, corrected_input

# Streamlit UI
st.title("Medical Chatbot")

# User input
user_input = st.text_input("Your question:")

if user_input:
    answer, source, corrected_input = find_exact_match(user_input)

    if answer is None:
        answer, source, corrected_input = find_best_match(user_input)

    st.write(f"Corrected Input: {corrected_input}")  # Display the corrected input

    if answer != "Sorry, I couldn't find a close enough match." and len(answer) > 500:
        user_choice = st.selectbox("The answer is too big. Do you want a summarized answer?", options=["No", "Yes"])
        if user_choice == "Yes":
            answer = summarize_answer(answer)

    formatted_answer = beautify_answer(answer)
    st.write(f"Answer:\n{formatted_answer}")

    if source:
        st.write(f"Source: {source}")
